#! /bin/bash

#SBATCH --partition=thchem
#SBATCH --time=00-24:00:00
#SBATCH --mem=2000
#SBATCH -N 1 -n 4
#SBATCH --exclude=cn06,cn07,cn08,cn09,cn10,cn11,cn12,cn30,cn31,cn54,cn58,cn59,cn60,cn61,cn62,cn63,cn69,cn73,cn85,cn86,cn87
#SBATCH --output=/home/ibatashev/MCES/SLURM/slurm-%A.out
#SBATCH --chdir=/scratch/ibatashev

#NOTE: change "LOGINNAME" into own login name throughout
#NOTE: /scratch/LOGINNAME should be an existing directory on all possible clusternodes you select
#NOTE: /home/LOGINNAME/SLURM should be an existing directory

# use bash as shell
# select partition: thchem, thchemhp, thchemdebug, or cncz
# time: days, hours, minutes, second
# memory in MB
# -N nodes (always 1), -n cores
# nodes in partition that are excluded,
#   the thchem partition has: cn06,cn07,cn08,cn09,cn10,cn11,cn12,cn21,cn22,cn23,cn30,cn31,cn60,cn61,cn62,cn63,cn69,cn72,cn73,cn85,cn86,cn87,cn58,cn59
#   history: cn06-cn09: the MTIN nodes
#            cn21-cn23: the IPP nodes
#   the cncz partition has: cn00,cn13,cn99
# global location for stderr, can use /vol/temp alternatively
# prevening an error message by starting in /scratch/LOGINNAME (should exist!) on run node

# ----------------------------------------------------------------------------------------
# BEWARE: this job is for using the default, i.e. open MPI, as installed on the cluster.
# The path to the INTEL MPI should NOT be set. Do not source the INTEL paths.
# The path needed for INTEL mkl, scaLAPACK and FFTW is set in mpirun.
# ----------------------------------------------------------------------------------------

# This selects the vasp executable
# ubuntu16:
# exe=/vol/thchem/dewijs/vasp/exe/vasp_gam.5.4.4.ifort19.opmi
# exe=/vol/thchem/dewijs/vasp/exe/vasp_ncl.5.4.4.ifort19.opmi
# exe=/vol/thchem/dewijs/vasp/exe/vasp_std.5.4.4.ifort19.opmi
# ubuntu18:
# exe=/vol/thchem/dewijs/vasp/exe/vasp_gam.5.4.4.ifort19.ubuntu18.ompi
# exe=/vol/thchem/dewijs/vasp/exe/vasp_ncl.5.4.4.ifort19.ubuntu18.ompi

# VASP 5
#exe=/vol/thchem/dewijs/vasp/exe/vasp_std.5.4.4.ifort19.ubuntu18.ompi
# VASP 6  to use BEXT
exe=/vol/thchem/dewijs/vasp/exe/vasp_std.Ivan.ifort19.ubuntu18.ompi

# needed
ulimit -s unlimited
ulimit -s

# environment variables:
#   $SLURM_JOBID    the number of the job
#   $SLURM_SUBMIT_HOST  the node on which the job was submitted
#   $SLURM_SUBMIT_DIR   the directory on this node from where the job was submitted
echo ""
echo "\$SLURM_JOBID       "$SLURM_JOBID
echo "\$SLURM_SUBMIT_HOST "$SLURM_SUBMIT_HOST
echo "\$SLURM_SUBMIT_DIR  "$SLURM_SUBMIT_DIR
echo ""

# Make unique directory on host that runs the program,
# prevent "others" from reading, etc, and "group" from writing,
# and copy (well... rsync) the inputfiles to this unique directory,
# and go into this unique directory.
# NOTE: /scratch/LOGINNAME should already be present!

mkdir /scratch/ibatashev/rundir.$SLURM_JOBID
chmod o-rwx /scratch/ibatashev/rundir.$SLURM_JOBID
chmod g-w /scratch/ibatashev/rundir.$SLURM_JOBID


# ----------------------------------------------------------------------------------------
#  __  __    _____   ______    _____
# |  \/  |  / ____| |  ____|  / ____|
# | \  / | | |      | |__    | (___
# | |\/| | | |      |  __|    \___ \
# | |  | | | |____  | |____   ____) |
# |_|  |_|  \_____| |______| |_____/
# ----------------------------------------------------------------------------------------

# File structure that must exist for correct exucution:

# -|MCES (directory where everything related to MCES happens - any name works)
# --*executor (this script)
# --|donedir (empty folder to put results for compledtely processed entries, from here one can safely retrieve results, even during screening process)
# --|inputdir
#  --|IDNUMBER (a directory for each compound)
#   ---|undeformed (optional)
#   ---|deformation1 (optional)
#   ---|... (as many subfolders as there are deformations)
# --|outdir (empty folder to put run results into while some of the subjobs are not yet finished)
# ---|fail (empty folder inside outdir to put failed runs into)
# --|SLURM (empty folder to put slurm output files into)


### setting variables ###

jobID=$SLURM_JOBID
workdir="/scratch/ibatashev/rundir.$SLURM_JOBID"
inputdir="$SLURM_SUBMIT_DIR/inputdir"
outdir="$SLURM_SUBMIT_DIR/outdir"
badlist="$SLURM_SUBMIT_DIR/badlist"
warnlist="$SLURM_SUBMIT_DIR/warnlist"
rerunlist="$SLURM_SUBMIT_DIR/rerunlist"
donedir="$SLURM_SUBMIT_DIR/donedir"

### defining functions ###

vasp_runner(){
  # function to call vasp executable
  cd /scratch/ibatashev/rundir.$SLURM_JOBID
  mpirun -x LD_LIBRARY_PATH=/vol/opt/intelcompilers/intel-2019/compilers_and_libraries_2019.1.144/linux/mkl/lib/intel64 $exe 1>stdout.out 2>/dev/null
  #echo "/home/ibatashev/SLURM/slurm-"$SLURM_JOBID".out" >> slurm_stder.$SLURM_JOBID
  #scp slurm_stder.$SLURM_JOBID $SLURM_SUBMIT_HOST:$SLURM_SUBMIT_DIR

  if [ -f "stdout" ]
  then
  rm stdout
  fi
  if [ -f "stderr" ]
  then
  rm stderr
  fi

  cd "$SLURM_SUBMIT_DIR"
  }


zip_clean(){
  # Function to zip important VASP output files & delete everything else. Takes directory as argument
  for file in $(find $1 -maxdepth 1 -mindepth 1 -type f ! -name '.*' -printf '%f\n')
  do
    if [[ "$file" != "OUTCAR" && "$file" != "OSZICAR" && "$file" != "IBZKPT" && "$file" != "vasprun.xml" && "$file" != "DOSCAR" && "$file" != *.out && "$file" != "$jobID" && "$file" != "fail" && "$file" != "warning" && "$file" != "rerun_attemped" ]]
    then
      rm -f "$1/$file"
    fi
  done
  cd "$1" && tar -zcf "../rundir.$SLURM_JOBID.tar.gz" * && cd $SLURM_SUBMIT_DIR
  }


k_sigma_test(){
  # Function to test choice of kpoint and sigma values, takes path to calculation folder as argument
  N_atoms=$(grep  -A 1 "Atomic configuration"  "$1/OUTCAR" | tail -1 | awk '{print$1}')
  E_wo_entropy=$(grep -A 2  "free  energy   TOTEN" "$1/OUTCAR"  | tail -1 | awk '{print $4}')
  F=$(grep "free  energy   TOTEN" "$1/OUTCAR"  | tail -1 | awk '{print $5}')
  E0=$(grep -A 2  "free  energy   TOTEN" "$1/OUTCAR"  | tail -1 | awk '{print $7}')

  E_diff1=$(awk "BEGIN { dif = (-( $F - ($E0))/$N_atoms); printf \"%.8f\", dif }") # the difference dE between F (free energy) and and E0 (sigma->0) is smaller than the accuracy from expected convergence
  E_diff2=$(awk "BEGIN { dif = (-( $F - ($E_wo_entropy))/$N_atoms); printf \"%.8f\", dif }") # the difference dE between F (free energy) and energy without entropy is smaller than the accuracy

  if (( $(echo "$E_diff1 < 0.001" |bc -l) )) || (( $(echo "$E_diff2 < 0.001" |bc -l) )) ; then # if either of above Energy differences is above 1meV than a warning is issued
    kpoint_sigma=false
  else
    kpoint_sigma=true
  fi
  echo "sigma and k-points checked"
  }


mag_field_test(){
  tot_moment=$(grep "tot"  "$1/OUTCAR" | tail -2 | head -1 | awk '{print$NF}')
  volume=$(grep "volume of cell" "$1/OUTCAR" | tail -1 | awk '{print$NF}')
  pi=3.141592653
  mag_field=$(awk "BEGIN { field = ( (4*$pi*0.1*$tot_moment*9.2741)/$volume ); printf \"%.8f\", field }")
  if (( $(echo "$mag_field > 0.45" |bc -l) )) ; then # if field is below our limit after calculation a warning is issued
    small_mag_field=false
  else
    small_mag_field=true
  fi
  echo "magnetic field checked"
  }


convergence_test_EDIFF(){
  # Function to test if chosen EDIFF has been reached, takes path to calculation folder as argument
  dE=$(grep "RMM" "$1/OSZICAR"  | tail -1 | awk '{print $4}' | tr E e | awk '{print $1 < 0 ? -$1 : $1}' | xargs printf "%.8f")
  deps=$(grep "RMM" "$1/OSZICAR"  | tail -1 | awk '{print $5}' | tr E e | awk '{print $1 < 0 ? -$1 : $1}' | xargs printf "%.8f")
  EDIFF=$(grep "EDIFF" "$1/INCAR"  | tail -1 | awk '{print $3}')
  if (( $(echo "$dE < $EDIFF" |bc -l) )) && (( $(echo "$deps < EDIFF" |bc -l) )) ; then # if all three checks are passed then calculation is converged
    converged_EDIFF=true
  else
    converged_EDIFF=false
  fi
  echo "EDIFF convergence checked"
  }


convergence_test_step(){
  # Function to test if number of RMM steps is suspiciously large, takes path to calculation folder as argument

  Algo=$(grep "ALGO" "$1/INCAR"  | tail -1 | awk '{print $3}')

  if [ "$Algo" = Normal ] ; then
    step=$(grep "DAV" "$1/OSZICAR"  | tail -1 | awk '{print $2}')
  elif [ "$Algo" = Fast ] ; then
    step=$(grep "RMM" "$1/OSZICAR"  | tail -1 | awk '{print $2}')
  fi

  if (( $(echo "$step < 70" |bc -l) )) ; then
    converged_step=true
  else
    converged_step=false
  fi
  echo "RMM step convergence checked"
}

symmetry_test(){
  # Function to check if vasp detected a symmetry error
  if grep -q "change SYMPREC in the INCAR file" "$1/OUTCAR"; then
    sym_failure=true
  elif grep -q "internal error in subroutinePOSMAP:" "$1/OUTCAR"; then
    sym_failure=true
  elif grep -q "internal error in subroutine IBZKPT:" "$1/OUTCAR"; then
    sym_failure=true
  elif grep -q "internal error in subroutine INVGRP:" "$1/OUTCAR"; then
    sym_failure=true
  elif grep -q "internal error in subroutineRHOSYG:" "$1/OUTCAR"; then
    sym_failure=true
  else
    sym_failure=false
  fi

  echo "symmetry checked"
}

processing_results(){
  echo "processing started"
  # Function to analyse how successful was the calculation, takes outputdir/entry/subfolder as argument
  k_sigma_test "$workdir"
  convergence_test_EDIFF "$workdir"
  convergence_test_step "$workdir"
  mag_field_test "$workdir"
  symmetry_test "$workdir"

  # We first check if accuracy is reached, if not - this is a failed run, then we check for RMM step etc.
  # Failures are mutually exclusive, so they are checked from more severe to less severe, once a bad result is triggered
  # all other failure conditions are not checked.

  # Bad result 1: Occupied highest bands
  if grep -q "Your highest band is occupied" "$workdir/OUTCAR"; then
    echo "Highest band occupied at some k-points"
    echo "$entry $1 | Highest band occupied at some k-points" >> $badlist
    echo "Highest band occupied at some k-points" > "$1/fail"
    failure=true
  # Bad result 2: Symmetry recognition problems
  elif [ "$sym_failure" = true ] ; then
    echo "Symmetry recognition problems"
    echo "$entry $1 | Symmetry recognition problems" >> $badlist
    echo "Symmetry recognition problems" > "$1/fail"
    failure=true
  # Bad result 3: Ediff accuracy not reached
  elif [ "$converged_EDIFF" = false ] ; then
    echo "run failed, set accuracy not reached: dE is $dE, deps is $deps"
    echo "$entry $1 | set accuracy not reached: dE is $dE, deps is $deps" >> $badlist
    echo "run failed, set accuracy not reached: dE is $dE, deps is $deps" > "$1/fail"
    failure=true
  # Bad result 4: Too many steps:
  elif [ "$converged_step" = false ] ; then
    echo "run failed, too many steps: step is $step"
    echo "$entry $1 | step is $step" >> $badlist
    echo "run failed, too many steps: step is $step" > "$1/fail"
    failure=true

  # Good result:
  else
    failure=false
    rm "$1/fail"
    # run is a success, now we check for warnings. Warnings are NOT mutially exlusive, i.e. we can have several warnings for the same run.
  # Warning 1: sigma and k-point are poorly chosen
    if [ "$kpoint_sigma" = true ] ; then
      echo "sigma and k-point are poorly chosen"
      echo "$entry $1 | sigma and k-point are poorly chosen: Entropy: $E_diff2 eV, sigma -> 0: $E_diff1 eV " >> $warnlist
      echo "sigma and k-point are poorly chosen: Entropy: $E_diff2 eV, sigma -> 0: $E_diff1 eV " > "$1/warning"
    fi
  # Warning 2: magnetic field after calculation is smaller than expeced
    if [ "$small_mag_field" = true ] && [ "$undeformed" = true ] ; then
      echo "magnetic field is below expected threshold"
      echo "$entry $1 | magnetic field is below expected threshold: M = $mag_field" >> $warnlist
      echo "magnetic field is below expected threshold: M = $mag_field" > "$1/warning"
    fi
  fi

  echo "results processed"
}


convergence_fail_check(){
  echo "Checking first run for convergence failure"
  # Function to analyse how successful was the convergence, takes outputdir/entry/subfolder as argument
  # Runs vasp again (only once, obviously) if first check fails
  # This is a smaller version of processing_results() that does not generate any output
  convergence_test_EDIFF "$workdir"
  convergence_test_step "$workdir"

  # Convergence problem 1: Ediff accuracy not reached
  if [ "$converged_EDIFF" = false ] ; then
    echo "FAILURE: set accuracy not reached: dE is $dE, deps is $deps, performing a rerun"
    echo "$entry $1 | Rerun performed after set accuracy not reached: dE was $dE, deps was $deps" >> $rerunlist
    echo "$entry $1 | Rerun performed after set accuracy not reached: dE was $dE, deps was $deps"> "$1/rerun_attemped"
    convergence_failure=true
  # Convergence problem 2: Too many RMM steps:
  elif [ "$converged_step" = false ] ; then
    echo "FAILURE: too many steps: step is $step, performing a rerun"
    echo "$entry $1 | Rerun performed after too many steps: step was $step" >> $rerunlist
    echo "$entry $1 | Rerun performed after too many steps: step was $step"> "$1/rerun_attemped"
    convergence_failure=true
  # Good result:
  else
    convergence_failure=false
  fi

  if [ $convergence_failure = true ] ; then
    echo "First run failed, attepting to rerun using obtained CHGGAR"
    cd "$workdir"
    echo "" >> INCAR
    echo "ICHARG = 1" >> INCAR
    echo "NELMDL = 10"  >> INCAR
    echo "calling vasp to run again"
    vasp_runner
    echo "vasp finished the second attempt"
  fi
}


symmetry_fail_check(){
  # function to detect if symmetry error occurs and deal with it.
  # Runs VASP once if failure is detected, now with lower SYMPREC - this usually solves most such cases
  echo "Checking first run for symmetry recognition failure"
  symmetry_test "$workdir"

  if [ "$sym_failure" = true ] ; then
    echo "FAILURE: Symmetry recognition problem, performing rerun with lower SYMPREC"
    echo "$entry $1 | Rerun performed after symmetry error" >> $rerunlist
    echo "$entry $1 | Rerun performed after symmetry error" > "$1/rerun_attemped"
    cd "$workdir"
    echo "" >> INCAR
    echo "SYMPREC = 0.0001" >> INCAR
    echo "calling vasp to run again"
    vasp_runner
    echo "vasp finished the second attempt"
  fi
}

### Main part ###
sleep $((RANDOM % 60))
echo "Starting..."

# Main loop that walks through directory with our database and tries to find something to run
for entry in $(find $inputdir -maxdepth 1 -mindepth 1 -type d ! -name '.*' -printf '%f\n') # NOTE: will fail for filenames containing spaces and similar, but we should't have them anyway
do
  # First we declare paths to work with for chosen entry
  echo "Trying entry $entry"

  # setting directory to work with for this entry
  entry_path="$inputdir/${entry:?}" # extra caution on a slightly dangerous move: we don't want to delete "/" if both workdir and entry are NULL for some reason

  # For each entry one of the following can happen:
  ###   Case 1:  Cleanup of an empty folder      ###
  if  [ -z "$(ls -A "$entry_path")" ]; then
    # cleaning up after other scripts if we find empty directory we delete it and try another entry
    echo "$entry folder is empty therefore being removed, will try another entry"
    rm -r "$entry_path"

    mv "$outdir/$entry" "$donedir/$entry" # move results for fully completed entry (undeformed and all deformations) to separate folder for pickup
    continue

  ###   Case 2:   Undeformed structure calculation     ###
  elif [[ -d "$entry_path/undeformed" ]]; then
    undeformed_run=true # flag to tell other functions that this is an undeformed run
    # undeformed exists in entry folder => it is either in progress or not yet done
    # setting up dirs to work with
    undeformed_path="${inputdir:?}/${entry:?}/undeformed"
    path_out="$outdir/$entry/undeformed"
    path_out_fail="$outdir/fail/$entry/undeformed"
    # Check if other script is already working with it:
    busy_flag="$undeformed_path/busy"
    fail_flag="$undeformed_path/fail"


    if [[ -e "$busy_flag" ]]; then
      echo "$entry undeformed structure is being used by other executor (found a busy file), will try another entry"
      continue
    # If not we can start working with it
    else
    # 0 add stopfile to claim this job
      echo "$SLURM_JOBID" > "$busy_flag"

    # 1. copy contents of the undeformed to workdir
      rsync -av $SLURM_SUBMIT_HOST:${undeformed_path:?}/* $workdir
      echo "$entry undeformed structure is good to go, files copied to workdir"
      echo "***"

    # 2. run vasp from workdir
      echo "calling vasp to run $entry undeformed structure "
      echo "Timeout fail (or not calculated at all)" > "$fail_flag" # a file to track failure due to timeout, would be removed if processing_results finishes before job is cancelled by slurm
      vasp_runner
      echo "vasp finished"
      echo "***"


    # 3. check output to see the results and act accordingly:
      mkdir "$outdir/$entry" # create folder for the entry in the outdir
      mkdir "$path_out" # create undeformed subfolder in outdir/entry

      symmetry_fail_check "$path_out"  # if we detect a failure we attempt to fix it by changing SYMPREC
      echo "***"
      convergence_fail_check "$path_out" # if we detect a failure we attempt to fix it by continuing calculation with CHGCAR from previous run
      echo "***"
      processing_results "$path_out" # analyse results again
      echo "***"
      if [ $failure = true ] ; then
        echo "First run and rerun failed, results placed in outdir, no need for deformations - removing $entry from workdir"
        rm -r "$entry_path" # remove whole directory for this entry - no need for deformations if undeformed structure failed

      else
        echo "Success, results placed in outdir, undeformed folder removed"
        rm -r "$undeformed_path" # remove entry/undeformed from inputdir
      fi

    # 4. Saving results
      rsync -av $workdir/OUTCAR $SLURM_SUBMIT_HOST:$path_out/OUTCAR
      zip_clean "$workdir"
      rsync -av $workdir.tar.gz $SLURM_SUBMIT_HOST:$path_out/rundir.$SLURM_JOBID.tar.gz
      echo "***"
    # 5. Exit loop and delete the folder we were working in - script stops after one vasp calculation regardless of result
      cd ..
      rm -r "$workdir"
      rm "$workdir.tar.gz"
      echo "$entry undeformed structure calculated. Exiting."
      break # A single job finished in some way - we break the main loop going through entries
    fi

  ###   Case 3: Deformed structure calculation   ###
  else
    undeformed_run=false # flag to tell other functions that this is a deformation run
    # undeformed is not in directory => looping through all deformation folders to find which one we can run
    echo "***"
    echo "$entry undeformed structure seems to be already completed, will try the deformations"
    for deformation in $(find "$entry_path" -maxdepth 1 -mindepth 1 -type d ! -name '.*' -printf '%f\n')
    do
      # setting up dirs to work with
      def_path="${inputdir:?}/${entry:?}/$deformation"
      path_out="$outdir/$entry/$deformation"
      # check if other script is already working with it:
      busy_flag="$def_path/busy"
      fail_flag="$def_path/fail"

      if [[ -e "$busy_flag" ]]; then
        echo "Deformation $deformation is being used by other executor (found a busy file), will try another deformation"
        jobdone=false # a flag that will tell us if any real work (vasp calculation) was done for this entry
        continue
      # If not we can start working with it
      else
      # 0 add stopfile to claim this job
         echo "$SLURM_JOBID" > "$busy_flag"

      # 1. copy contents of the deformation folder to workdir
        rsync -av $SLURM_SUBMIT_HOST:${def_path:?}/* $workdir
        echo "$entry $deformation is good to go, files moved to workdir"
        echo "***"

      # 2. run vasp from workdir
        echo "calling vasp to run $entry $deformation"
        echo "Timeout fail (or not calculated at all)" > "$fail_flag" # a file to track failure due to timeout, would be removed if processing_results finishes before job is cancelled by slurm
        vasp_runner
        echo "vasp finished"
        echo "***"


      # 3. grep on output to see the results and act accordingly
        mkdir "$path_out" # prepare subfolder for deformation, we expect there is already outdir/entry/ which is created during undeformed calculation

        symmetry_fail_check "$path_out" # if we detect a failure we attempt to fix it by changing SYMPREC
        echo "***"
        convergence_fail_check "$path_out" # if we detect a failure we attempt to fix it by continuing calculation with CHGCAR from previous run
        echo "***"
        processing_results "$path_out" # analyse results again
        echo "***"
        if [ $failure = true ] ; then
          echo "First run and rerun failed, results placed in outdir"
        else
          echo "Success, results placed in outdir"
        fi
        rm -r "$def_path" # deformation folder is removed from inputdir/entry

      # 4. Saving results:
        rsync -av $workdir/OUTCAR $SLURM_SUBMIT_HOST:$path_out/OUTCAR
        zip_clean "$workdir"
        rsync -av $workdir.tar.gz $SLURM_SUBMIT_HOST:$path_out/rundir.$SLURM_JOBID.tar.gz
        echo "***"
      # 5. Exit loop and delete the folder we were working in - script stops after one vasp calculation regardless of result
        cd ..
        rm -r "$workdir"
        rm "$workdir.tar.gz"
        echo "$entry deformation $deformation calculated. Exiting."
        jobdone=true # make a flag to break the main loop going trough all entries
        break        # break loop going through deformations
      fi
    done
    if [ $jobdone = true ] ; then  # a single deformation finished => we break the loop going through entries
      break
    elif [ $jobdone = false ] ; then # no deformation run can be executed for this entry => we try the next one
      echo "Seems like there aren't any deformations left to do for $entry, will try another entry"
      continue
    fi
  fi # all cases checked
done # main loop closed
echo "***"
echo "Bye"
